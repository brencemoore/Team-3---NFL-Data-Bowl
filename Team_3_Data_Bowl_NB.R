#Team 3:Samuel Hartmann, Logan McDavid, Brence Moore, Nathan Lamb

#Code for reading in and sorting data written by Samuel
#load tidyverse and plays.csv
library(tidyverse)
library(tidymodels)
library(discrim)
master_data <- read.csv("plays.csv")

#Select only gameId, playID, quarter, down, yardsToGo, defensiveTeam, gameClock, pff_passCoverage, and pff_manZone
working_data <- master_data |> select(gameId, playId, quarter, down, yardsToGo, defensiveTeam, gameClock, pff_passCoverage, pff_manZone)
#summary(working_data)

#Review Na and Other Values
Na_data <- master_data |> filter(is.na(pff_manZone))
Other_data <- master_data |> filter(pff_manZone == 'Other')
#print(Na_data$playDescription)
#print(Other_data$playDescription)

#remove row with NA values
cleaned_data <- na.omit(working_data)

#remove other values
cleaned_master <- cleaned_data |> filter(pff_manZone != 'Other')
#summary(cleaned_master)

#get counts of each defensive alignment
count_defs <- cleaned_master |> count(pff_passCoverage)
#print(count_defs)

#clean Cover-3 of variants and Cover-1 of Cover-1 Double
ready_master <- cleaned_master |> mutate(pff_passCoverage = case_when(
  pff_passCoverage == "Cover-3 Cloud Left" ~ "Cover-3",
  pff_passCoverage == "Cover-3 Cloud Right" ~ "Cover-3",
  pff_passCoverage == "Cover-3 Double Cloud" ~ "Cover-3",
  pff_passCoverage == "Cover-1 Double" ~ "Cover-1",
  TRUE ~ pff_passCoverage))

#get counts of each defensive alignment after cleaning
count_defs <- ready_master |> count(pff_passCoverage)
print(count_defs)

#get list of team Ids
team_Ids <- unique(ready_master$defensiveTeam)
#print(team_Ids)

#AFC East
BUF_data <- ready_master  |> filter(defensiveTeam == 'BUF')
MIA_data <- ready_master  |> filter(defensiveTeam == 'MIA')
NJY_data <- ready_master  |> filter(defensiveTeam == 'NYJ')
NE_data <- ready_master  |> filter(defensiveTeam == 'NE')

#AFC West
KC_data <- ready_master  |> filter(defensiveTeam == 'KC')
LAC_data <- ready_master  |> filter(defensiveTeam == 'LAC')
DEN_data <- ready_master  |> filter(defensiveTeam == 'DEN')
LV_data <- ready_master  |> filter(defensiveTeam == 'LV')

#AFC North
PIT_data <- ready_master  |> filter(defensiveTeam == 'PIT')
BAL_data <- ready_master  |> filter(defensiveTeam == 'BAL')
CIN_data <- ready_master  |> filter(defensiveTeam == 'CIN')
CLE_data <- ready_master  |> filter(defensiveTeam == 'CLE')

#AFC South
HOU_data <- ready_master  |> filter(defensiveTeam == 'HOU')
IND_data <- ready_master  |> filter(defensiveTeam == 'IND')
TEN_data <- ready_master  |> filter(defensiveTeam == 'TEN')
JAX_data <- ready_master  |> filter(defensiveTeam == 'JAX')

#NFC East
PHI_data <- ready_master  |> filter(defensiveTeam == 'PHI')
WAS_data <- ready_master  |> filter(defensiveTeam == 'WAS')
DAL_data <- ready_master  |> filter(defensiveTeam == 'DAL')
NYG_data <- ready_master  |> filter(defensiveTeam == 'NYG')

#NFC West
ARI_data <- ready_master  |> filter(defensiveTeam == 'ARI')
SF_data <- ready_master  |> filter(defensiveTeam == 'SF')
LA_data <- ready_master  |> filter(defensiveTeam == 'LA')
STL_data <- ready_master  |> filter(defensiveTeam == 'STL')

#NFC North
DET_data <- ready_master  |> filter(defensiveTeam == 'DET')
MIN_data <- ready_master  |> filter(defensiveTeam == 'MIN')
GB_data <- ready_master  |> filter(defensiveTeam == 'GB')
CHI_data <- ready_master  |> filter(defensiveTeam == 'CHI')

#NFC South
ATL_data <- ready_master  |> filter(defensiveTeam == 'ATL')
TB_data <- ready_master  |> filter(defensiveTeam == 'TB')
NO_data <- ready_master  |> filter(defensiveTeam == 'NO')
CAR_data <- ready_master  |> filter(defensiveTeam == 'CAR')
#end code generated by Samuel

count_defs <- ready_master |> count(pff_passCoverage)
print(count_defs)
#Samuel Naive Bayes

#split quarter, down, yards to go, gameclock, and pass_coverage off into new df
pass_coverage <- ready_master %>%
  select(quarter, down, yardsToGo, gameClock, pff_passCoverage)

#set seed
set.seed(110)

# Convert time to seconds
pass_coverage <- pass_coverage |>
  mutate(gameClockSec = sapply(strsplit(gameClock, ":"), function(x) {
    minutes <- as.numeric(x[1])
    seconds <- as.numeric(x[2])
    minutes * 60 + seconds
  }))

# Split the data into training and testing sets stratafied on pff_passCoverage
data_split <- initial_split(pass_coverage, prop = 0.70, strata = pff_passCoverage)
train_data <- training(data_split)
test_data <- testing(data_split)

# Create a recipe with quarter, down, yardsToGo, and gameClockSec
coverage_recipe <- recipe(pff_passCoverage ~quarter + down + yardsToGo + gameClockSec, data = train_data)

# Prepare the recipe
prepared_recipe <- prep(coverage_recipe)

# Bake the training and test data based on recipe
train_baked <- prepared_recipe |> bake(new_data = NULL)
test_baked <- prepared_recipe |> bake(new_data = test_data)

#marticize the train data
x <- train_baked |> select(-pff_passCoverage) |> as.matrix()

#extract the test data
y <- train_baked$pff_passCoverage

# Fit the Multinomial Naive Bayes model using naivebayes::multinomial_naive_bayes
mnb <- naivebayes::multinomial_naive_bayes(x, y, laplace = 1)

# Add the predictions from the model onto the dataset
train_predict <- train_data |>  mutate(.pred_class = predict(mnb, x))

# Create a confusion matrix for the training data using the predictions stored in train_predict
train_confusion_matrix <- table(Predicted = train_predict$.pred_class, Actual = train_predict$pff_passCoverage)
print("Training Confusion Matrix:")
print(train_confusion_matrix)

# Predict from test data
test_matrix <- test_baked |> select(-pff_passCoverage) |> as.matrix()
test_predict <- test_data |> mutate(.pred_class = predict(mnb, test_matrix))

# Create a confusion matrix for the test data
test_confusion_matrix <- table(Predicted = test_predict$.pred_class, Actual = test_data$pff_passCoverage)
print("Test Confusion Matrix:")
print(test_confusion_matrix)

# Calculate accuracy for the test data
test_accuracy <- sum(test_predict$.pred_class == test_data$pff_passCoverage) / nrow(test_data)
print(paste("Test Accuracy:", round(test_accuracy, 2)))

# Convert the confusion matrix to a data frame
confusion_long <- as.data.frame(test_confusion_matrix)

# Check the structure of the confusion_long data frame
str(confusion_long)

# Rename columns to make them clearer
colnames(confusion_long) <- c("Predicted", "Actual", "Count")

# Create a new column for Correct/Incorrect prediction
confusion_long <- confusion_long %>%
  mutate(Prediction = ifelse(Actual == Predicted, "Correct", "Incorrect"))

# Create the ggplot visualization
ggplot(confusion_long, aes(x = Actual, y = Count, fill = Prediction)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Confusion Matrix Visualization",
       x = "Actual Class",
       y = "Count",
       fill = "Prediction") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))